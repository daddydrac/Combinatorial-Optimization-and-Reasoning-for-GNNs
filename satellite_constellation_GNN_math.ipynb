{"cells": [{"cell_type": "markdown", "id": "a459b58a", "metadata": {}, "source": ["\n", "# GNNs for Combinatorial Optimization: Satellite Constellation Management\n", "\n", "This notebook provides a detailed implementation of Graph Neural Networks (GNNs) for solving combinatorial optimization problems in satellite constellation management. Each code block is paired with LaTeX equations and explanations.\n"]}, {"cell_type": "markdown", "id": "4c039786", "metadata": {}, "source": ["\n", "### Representing the Problem as a Graph\n", "\n", "The problem is represented as a graph:\n", "\n", "$$\n", "G = (V, E)\n", "$$\n", "\n", "where:\n", "\n", "- $V$ is the set of nodes (e.g., satellites).\n", "- $E$ is the set of edges representing communication links.\n", "\n", "Each node $v \\in V$ has features $\\mathbf{x}_v$ and each edge $(u, v) \\in E$ has features $\\mathbf{e}_{u,v}$.\n", "\n", "### Cost Function and Objective\n", "\n", "The cost function for optimization is given as:\n", "\n", "$$\n", "c(S) = \\sum_{v \\in S} w(v) + \\sum_{(u, v) \\in S} w(u, v)\n", "$$\n", "\n", "where $w(v)$ and $w(u, v)$ are node and edge weights, respectively.\n", "\n", "The objective is to find:\n", "\n", "$$\n", "S^* = \\text{argmin}_{S \\in \\mathcal{F}} c(S)\n", "$$\n", "\n", "subject to constraints $\\mathcal{F} \\subseteq 2^V$."]}, {"cell_type": "code", "execution_count": null, "id": "24bbaefa", "metadata": {}, "outputs": [], "source": ["\n", "# Step 1: Representing the Problem as a Graph\n", "import torch\n", "from torch_geometric.data import Data\n", "\n", "def prepare_satellite_graph(sat_positions, sat_features, links, link_features):\n", "    '''\n", "    Converts satellite constellation data into a PyG graph.\n", "    '''\n", "    # Edge index: [2, num_edges]\n", "    edge_index = torch.tensor(links, dtype=torch.long).t().contiguous()\n", "    \n", "    # Node features: [num_nodes, feature_dim]\n", "    x = torch.tensor(sat_features, dtype=torch.float)\n", "    \n", "    # Edge features: [num_edges, feature_dim]\n", "    edge_attr = torch.tensor(link_features, dtype=torch.float)\n", "    \n", "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n"]}, {"cell_type": "markdown", "id": "e5ea20a7", "metadata": {}, "source": ["### Node Embedding Update\n", "\n", "The node embeddings are updated iteratively using a GNN:\n", "\n", "$$\n", "\\mathbf{h}_v^{(t+1)} = \\text{Update}\\left(\\mathbf{h}_v^{(t)}, \\text{Aggregate}\\left(\\{\\mathbf{m}_{u \\to v}^{(t)} : u \\in \\mathcal{N}(v)\\}\\right)\\right)\n", "$$\n", "\n", "where:\n", "\n", "- **Messages**:\n", "\n", "$$\n", "\\mathbf{m}_{u \\to v}^{(t)} = \\phi_{\\text{message}}(\\mathbf{h}_u^{(t)}, \\mathbf{h}_v^{(t)}, \\mathbf{e}_{u,v})\n", "$$\n", "\n", "- **Aggregation**:\n", "\n", "$$\n", "\\text{Aggregate}(\\{\\mathbf{m}_{u \\to v}\\}) = \\text{AGG}(\\{\\mathbf{m}_{u \\to v}\\})\n", "$$\n", "\n", "- **Update**:\n", "\n", "$$\n", "\\mathbf{h}_v^{(t+1)} = \\phi_{\\text{update}}(\\mathbf{h}_v^{(t)}, \\text{Aggregate})\n", "$$"]}, {"cell_type": "code", "execution_count": null, "id": "607b3ad3", "metadata": {}, "outputs": [], "source": ["\n", "# Step 2: Graph Neural Network Framework\n", "from torch_geometric.nn import GATConv, EdgeConv\n", "import torch.nn.functional as F\n", "\n", "class SatelliteGNN(torch.nn.Module):\n", "    def __init__(self, input_dim, hidden_dim, output_dim):\n", "        super(SatelliteGNN, self).__init__()\n", "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)  # Graph Attention\n", "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=False)\n", "        self.edge_conv = EdgeConv(nn=torch.nn.Linear(2 * hidden_dim, hidden_dim))  # Edge-level\n", "        self.out = torch.nn.Linear(hidden_dim, output_dim)  # Final output layer\n", "\n", "    def forward(self, data):\n", "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n", "        \n", "        # Node embeddings\n", "        x = F.relu(self.conv1(x, edge_index))\n", "        x = F.relu(self.conv2(x, edge_index))\n", "        \n", "        # Edge prediction\n", "        edge_out = self.edge_conv(x, edge_index)\n", "        \n", "        # Node-level output (e.g., routing decisions)\n", "        node_out = self.out(x)\n", "        return node_out, edge_out\n"]}, {"cell_type": "markdown", "id": "702bd0a3", "metadata": {}, "source": ["\n", "## Step 3: Training\n", "\n", "The objective is to minimize latency and predict link failures.\n", "### Training\n", "\n", "To train the GNN, we:\n", "\n", "1. Initialize parameters $\\theta$.\n", "2. Convert the input data to a graph $G$.\n", "3. Perform $T$ layers of message passing to compute embeddings.\n", "4. Use a decoder to predict $S_{\\text{pred}}$.\n", "5. Compute the loss $\\mathcal{L}$.\n", "6. Update $\\theta$ via backpropagation.\n", "\n", "\n", "### Loss Function\n", "\n", "The loss function for supervised learning is given by:\n", "\n", "$$\n", "\\mathcal{L}_{\\text{sup}} = \\text{CrossEntropy}(S_{\\text{pred}}, S_{\\text{true}})\n", "$$\n", "\n", "For reinforcement learning, the loss function is:\n", "\n", "$$\n", "\\mathcal{L}_{\\text{RL}} = - \\mathbb{E}_{S \\sim \\pi_\\theta} [R(S)]\n", "$$\n", "\n", "The total loss combines both:\n", "\n", "$$\n", "\\mathcal{L} = \\mathcal{L}_{\\text{sup/RL}} + \\lambda \\mathcal{L}_{\\text{constraint}}\n", "$$\n", "\n", "#### Routing Optimization:\n", "\n", "$$\n", "\\mathcal{L}_{\\text{routing}} = \\text{CrossEntropy}(S_{\\text{pred}}, S_{\\text{true}})\n", "$$\n", "\n", "#### Link Quality Prediction:\n", "\n", "$$\n", "\\mathcal{L}_{\\mathrm{link}} = \\mathrm{MSE}(\\text{predictedlinks}, \\mathrm{truelinks})\n", "$$\n", "\n", "#### Combined Loss:\n", "\n", "$$\n", "\\mathcal{L} = \\alpha \\mathcal{L}_{\\text{routing}} + \\beta \\mathcal{L}_{\\text{link}}\n", "$$\n"]}, {"cell_type": "code", "execution_count": null, "id": "81ec0eba", "metadata": {}, "outputs": [], "source": ["\n", "# Step 3: Training\n", "def combined_loss(node_out, edge_out, true_routes, true_links, alpha=0.5, beta=0.5):\n", "    '''\n", "    Compute combined loss for satellite constellation management.\n", "    '''\n", "    routing_loss = F.cross_entropy(node_out, true_routes)\n", "    link_loss = F.mse_loss(edge_out, true_links)\n", "    return alpha * routing_loss + beta * link_loss\n"]}, {"cell_type": "markdown", "id": "dd074078", "metadata": {}, "source": ["\n", "## Step 4: Inference\n", "\n", "After training, use the GNN to predict routing paths and link qualities.\n", "Given a new graph $G$, we:\n", "\n", "1. Compute embeddings $\\mathbf{h}_v^{(T)}$ using the trained GNN.\n", "2. Decode $S_{\\text{pred}}$ from the embeddings.\n", "3. Evaluate $S_{\\text{pred}}$ for feasibility and quality.\n", "\n", "### Routing Path Prediction:\n", "\n", "$$\n", "S_{\\text{pred}} = \\text{argmax}(\\text{node\\_out})\n", "$$\n", "\n", "### Link Quality Prediction:\n", "\n", "$$\n", "\\text{edge\\_out} \\text{ represents predicted link qualities.}\n", "$$\n"]}, {"cell_type": "code", "execution_count": null, "id": "87789e76", "metadata": {}, "outputs": [], "source": ["\n", "def predict_routing(data, model, device):\n", "    model.eval()\n", "    data = data.to(device)\n", "    with torch.no_grad():\n", "        node_out, _ = model(data)\n", "    # Predicted routes\n", "    return node_out.argmax(dim=1) \n", "\n", "def predict_link_quality(data, model, device):\n", "    model.eval()\n", "    data = data.to(device)\n", "    with torch.no_grad():\n", "        _, edge_out = model(data)\n", "    # Predicted link qualities\n", "    return edge_out  \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Discounted Returns\n", "The discounted return at timestep \\( t \\) is computed as:\n", "$$\n", "G_t = R_t + \\gamma G_{t+1}\n", "$$\n", "Where:\n", "- \\( R_t \\) is the reward at timestep \\( t \\),\n", "- \\( \\gamma \\) is the discount factor (\\( 0 \\leq \\gamma \\leq 1 \\)),\n", "- \\( G_t \\) is the cumulative discounted reward starting from timestep \\( t \\).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2. Policy Loss\n", "The objective of the policy is to maximize the expected return:\n", "$$\n", "\\mathcal{L}_{\\text{policy}} = - \\mathbb{E}_{\\tau \\sim \\pi_\\theta} \\left[ G_t \\cdot \\log \\pi_\\theta(a_t | s_t) \\right]\n", "$$\n", "Where:\n", "- \\( \\pi_\\theta(a_t | s_t) \\) is the probability of taking action \\( a_t \\) in state \\( s_t \\),\n", "- \\( G_t \\) is the discounted return starting from timestep \\( t \\),\n", "- \\( \\tau \\) is a trajectory sampled under policy \\( \\pi_\\theta \\).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3. Value Loss\n", "The value network is trained to minimize the difference between predicted values and actual returns:\n", "$$\n", "\\mathcal{L}_{\\text{value}} = \\frac{1}{2} \\sum_t \\left( V_\\phi(s_t) - G_t \\right)^2\n", "$$\n", "Where:\n", "- \\( V_\\phi(s_t) \\) is the value function parameterized by \\( \\phi \\),\n", "- \\( G_t \\) is the discounted return.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 4. Total Loss\n", "The total loss combines the policy and value losses, with an optional entropy term to encourage exploration:\n", "$$\n", "\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{policy}} + \\lambda \\mathcal{L}_{\\text{value}} - \\beta \\mathcal{L}_{\\text{entropy}}\n", "$$\n", "Where:\n", "- \\( \\mathcal{L}_{\\text{entropy}} = - \\sum_a \\pi_\\theta(a | s) \\log \\pi_\\theta(a | s) \\) encourages exploration.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 5. GNN Message Passing\n", "Each node embedding \\( \\mathbf{h}_v^{(t+1)} \\) is updated using:\n", "$$\n", "\\mathbf{h}_v^{(t+1)} = \\phi_{\\text{update}} \\left( \\mathbf{h}_v^{(t)}, \\text{Aggregate} \\left( \\{ \\phi_{\\text{message}}(\\mathbf{h}_u^{(t)}, \\mathbf{h}_v^{(t)}, \\mathbf{e}_{u,v}) : u \\in \\mathcal{N}(v) \\} \\right) \\right)\n", "$$\n", "Where:\n", "- \\( \\phi_{\\text{message}} \\) is the message function,\n", "- \\( \\text{Aggregate} \\) is a permutation-invariant aggregation function (e.g., sum, mean, max),\n", "- \\( \\phi_{\\text{update}} \\) is the update function (e.g., an MLP),\n", "- \\( \\mathbf{e}_{u,v} \\) are edge features,\n", "- \\( \\mathcal{N}(v) \\) is the set of neighbors of node \\( v \\).\n"]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}